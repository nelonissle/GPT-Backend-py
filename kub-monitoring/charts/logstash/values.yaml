# Default values for logstash
nameOverride: ""
fullnameOverride: ""

# Namespace to deploy resources
namespace: gpt-monitoring

# Replicas for logstash deployment
replicaCount: 1

# Pod resources
resources:
  requests:
    cpu: "300m"
    memory: "512Mi"
  limits:
    cpu: "800m"
    memory: "1Gi"

# Image configuration
image:
  repository: docker.elastic.co/logstash/logstash
  tag: "8.6.0"
  pullPolicy: IfNotPresent

# Service configuration
service:
  type: ClusterIP
  ports:
    - name: beats
      port: 5044
      targetPort: 5044
      protocol: TCP
    - name: http
      port: 9600
      targetPort: 9600
      protocol: TCP

# Persistence configuration
persistence:
  enabled: true
  storageClass: "standard"
  size: "20Gi"
  accessMode: ReadWriteOnce

# Elasticsearch connection
elasticsearch:
  host: "elasticsearch"
  port: 9200
  user: "elastic"
  password: "changeme"
  useExistingSecret: false
  existingSecret: ""
  secretUserKey: "elasticsearch-user"
  secretPasswordKey: "elasticsearch-password"

# Logstash configuration
config:
  logstashJavaOpts: "-Xmx512m -Xms256m"
  pipelineWorkers: 2
  pipelineBatchSize: 125
  pipelineBatchDelay: 50
  queueCheckpointWrites: 1000
  
  # Logstash Pipeline Configuration
  pipeline:
    input: |
      input {
        beats {
          port => 5044
        }
        tcp {
          port => 5000
          codec => json
        }
      }
    filter: |
      filter {
        if [message] {
          mutate {
            add_field => { "[@metadata][debug]" => "Added by logstash" }
          }
          
          if [message] =~ /^\s*{/ {
            json {
              source => "message"
            }
          }
        }
      }
    output: |
      output {
        elasticsearch {
          hosts => ["${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}"]
          user => "${ELASTICSEARCH_USER}"
          password => "${ELASTICSEARCH_PASSWORD}"
          index => "gpt-backend-logs-%{+YYYY.MM.dd}"
        }
        stdout { codec => rubydebug }
      }
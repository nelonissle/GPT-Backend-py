# docker-compose.yml
services:
  kong-database:
    image: postgres:14
    container_name: kong-database
    env_file:
      - ./.env
    volumes:
      - kong_pgdata:/var/lib/postgresql/data
    networks:
      - gpt_backend_network
    restart: always

  kong-migrations:
    image: kong:latest
    container_name: kong-migrations
    command: kong migrations bootstrap
    env_file:
      - ./.env
    networks:
      - gpt_backend_network
    depends_on:
      - kong-database
    restart: "no"

  kong-gateway:
    image: kong:latest
    container_name: kong-gateway
    user: root
    env_file:
      - ./.env
    ports:
      - "8000:8000"    # HTTP Proxy
      - "8443:8443"    # HTTPS Proxy
      - "8001:8001"    # Admin API HTTP
      - "8444:8444"    # Admin API HTTPS
    volumes:
      - ./kong_logs:/var/log/kong
    networks:
      - gpt_backend_network
    depends_on:
      - kong-database
      - kong-migrations
    restart: always

  mongo_db:
    image: mongo:latest
    container_name: mongo_db
    env_file:
      - ./.env
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    networks:
      - gpt_backend_network
    restart: always

  auth_service:
    build: ./auth_service
    container_name: auth_service
    ports:
      - "8002:8002"
    env_file:
      - ./.env
    volumes:
      - ./auth_service:/app
    networks:
      - gpt_backend_network
    depends_on:
      - kong-gateway
    restart: always

  chat_service:
    build: ./chat_service
    container_name: chat_service
    command: uvicorn app.main:app --host 0.0.0.0 --port 8003
    ports:
      - "8003:8003"
    env_file:
      - ./.env
    volumes:
      - ./chat_service:/app
    networks:
      - gpt_backend_network
    depends_on:
      - kong-gateway
      - mongo_db
    restart: always

  admin_service:
    build: ./admin_service
    container_name: admin_service
    ports:
      - "8004:8004"
    env_file:
      - ./.env
    networks:
      - gpt_backend_network
    depends_on:
      - auth_service
      - chat_service
    restart: always

  # —————— Monitoring Stack ——————

  loki:
    image: grafana/loki:latest
    container_name: loki
    user: root
    ports:
      - "3100:3100"
    command: >
      -config.file=/etc/loki/local-config.yaml
      -config.expand-env=true
    volumes:
      - ./monitoring/loki-config.yaml:/etc/loki/local-config.yaml:ro
      - loki_chunks:/loki/chunks
      - loki_index:/loki/index
      - loki_cache:/loki/cache
      - loki_wal:/loki/wal
      - loki_compactor:/loki/compactor
    networks:
      - gpt_backend_network
    restart: always

  promtail:
   image: grafana/promtail:latest
   container_name: promtail
   ports:
    - "9080:9080"
   command:
    - "--config.file=/etc/promtail/promtail-config.yaml"
    - "--log.level=debug"
   volumes:
    - ./monitoring/promtail-config.yaml:/etc/promtail/promtail-config.yaml:ro
    - ./kong_logs:/var/log/kong:ro
    - /var/lib/docker/containers:/var/lib/docker/containers:ro
    - /var/run/docker.sock:/var/run/docker.sock:ro
   networks:
    - gpt_backend_network
   depends_on:
    - loki
   restart: always

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - prometheus_data:/prometheus
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
    networks:
      - gpt_backend_network
    restart: always

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    env_file:
      - ./.env
    volumes:
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=yourpassword
    depends_on:
      - prometheus
      - loki
    networks:
      - gpt_backend_network
    restart: always

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - gpt_backend_network
    restart: always
    environment:
      - OLLAMA_MODELS=llama3

volumes:
  mongo_data:
  kong_pgdata:
  prometheus_data:
  grafana_data:
  loki_chunks:
  loki_index:
  loki_cache:
  loki_wal:
  loki_compactor:
  ollama_data:

networks:
  gpt_backend_network:
    name: gpt_backend_network
